{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95322e8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e721f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On définie le path vers nos images\n",
    "\n",
    "custom_image_path = r'photos_usecase3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e5140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1= nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1= nn.ReLU()\n",
    "        self.pool1= nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2= nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2= nn.ReLU()\n",
    "        self.pool2= nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1  = nn.Linear(32*56*56,64)\n",
    "        self.relu3= nn.ReLU()\n",
    "        self.fc2  = nn.Linear(64,2) #2 output photos reportages & photos studios\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.pool1(self.relu1(self.conv1(x)))\n",
    "        x= self.pool2(self.relu2(self.conv2(x)))\n",
    "        x= x.view(-1,32*56*56)\n",
    "        x= self.relu3(self.fc1(x))\n",
    "        x= self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfff04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement du dataset\n",
    "dataset= ImageFolder(root=custom_image_path,transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e503b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On sépare le dataset entre ceux qui seront pour l'entrainement d'IA et ceux pour la validation (80/20)\n",
    "train_size = int(0.8*len(dataset))\n",
    "val_size = len(dataset)-train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset,[train_size,val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f2e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On crée le chargement des données\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04809050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On initialise le modele\n",
    "model = SimpleCNN()\n",
    "\n",
    "#On calcule l'efficacité du modele\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "\n",
    "epochs= 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bfa7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "            val_loss+= loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            val_corrects+= torch.sum(preds==labels.data)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_accuracy = val_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss: .4f}, Val loss: {val_loss: .4f}, Val accuracy: {val_accuracy: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aacb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sauvegarde le model actuel\n",
    "torch.save(model.state_dict(), 'custom_cnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8224668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Initialisation des variables\n",
    "pourcentage_studio = 0\n",
    "pourcentage_reportage = 0\n",
    "total_images = 0\n",
    "\n",
    "# Chemin vers le dossier test\n",
    "test_folder = r\"Photos_Test\"\n",
    "\n",
    "# Classes du modèle\n",
    "class_labels = ['photo reportage', 'photo studio']\n",
    "\n",
    "# Parcours tous les fichiers et sous-dossiers dans le dossier test\n",
    "for root, dirs, files in os.walk(test_folder):\n",
    "    for filename in files:\n",
    "        # Vérifie si le fichier est une image (en fonction des extensions)\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
    "            total_images += 1\n",
    "            image_path = os.path.join(root, filename)\n",
    "            \n",
    "            # Charge l'image\n",
    "            try:\n",
    "                image = Image.open(image_path)\n",
    "                image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Prédire avec le modèle\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(image_tensor)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                prediction = class_labels[predicted.item()]\n",
    "                print(f\"The image '{image_path}' is classified as: {prediction}\")\n",
    "                \n",
    "                # Comptabilise les prédictions correctes pour 'photo studio'\n",
    "                if prediction == 'photo studio':\n",
    "                    pourcentage_studio += 1\n",
    "                else:\n",
    "                    pourcentage_reportage+=1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file '{image_path}': {e}\")\n",
    "\n",
    "# Affiche les résultats\n",
    "if total_images > 0:\n",
    "    print(f\"The model detects photo studio out of {total_images} images nby: {pourcentage_studio * 100 / total_images:.2f}%\")\n",
    "    print(f\"The model detects photo reportage out of {total_images} images by: {pourcentage_reportage * 100 / total_images:.2f}%\")\n",
    "else:\n",
    "    print(\"No valid images found in the folder!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(image_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "class_labels = ['photo reportage','photo studio']\n",
    "prediction = class_labels[predicted.item()]\n",
    "\n",
    "print(f\"The image is classified as : {prediction}\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
